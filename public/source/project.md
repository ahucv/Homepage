#### Learning Collaborative Graphs and Correlation Filters for Multimodal Object Tracking, NSFC 2018.1-2020.12

- **Introduction:** The goal of multimodal object tracking is to track target objects robustly in challenging scenes and environmental conditions by leveraging multiple different yet complementary visual data. It plays a critical role in wide range of applications, such as visual surveillance, self-driving systems and robotics, due to its potentials in handling variety of challenging factors (low illumination, smog, background clutter, etc.). Existing multimodal tracking methods usually localize the object with a bounding box, in which the foreground object trackers/detectors are often disturbed by the introduced background information. To handle this problem, this project aims to learn a collaborative graph with image patches as nodes for multimodal tracking, in which the weight of each node indicates how likely it belongs to the foreground and edges are also weighted for indicating the appearance compatibility of two neighboring nodes. The optimized node weights are then incorporated into the object representation to achieve robust tracking. In addition, we also study a collaborative correlation filter to overcome the dependency of multimodal alignment in conventional methods. The collaborative correlation filter takes the relations of object locations and motions in different modalities into account to track the object collaboratively.

- **Featured Works**

#### Research and Applications on Video based Spatio-Temporal Structural Deep Models, NSFC 2019.1-2019.12

With the explosive growth of video data, it is urgent to utilize intelligence to achieve automatic analysis and understanding of video data. The existing methods are mostly limited to the isolated analysis of video images and therefore incapable of performing complex video analysis tasks in a real environment. The spatio-temporal structured description of video content is very crucial for complex video analysis. It contains a series of structural characteristics such as spatio-temporal association, target, component, and attribute correlations of the video, which form a structural system that spans spatially and temporally from macro to micro of the video. For this reason, this project intends to study deep learning based methods to fully exploit the temporal and spatial structure of complex video and build a spatio-temporal structural deep model of the video. Specifically, it includes, 1) modeling target spatiotemporal structural relationships based on dynamic spatio-temporal graph regional convolutional neural networks, 2) modeling component spatio-temporal structural relationships based on multi-task structured convolutional neural networks, and 3) the multi-granularity feature fusion based on the cascading spatio-temporal graph regional convolutional neural networks. On this basis, this project will form a weakly supervised video analysis framework based on the deep model with spatio-temporal structures of the video and conduct related applications. It will focus on the challenging issue of complex video analysis, and promote the development and application of deep video analysis methodologies oriented to the spatio-temporal structure.


#### General Temporal Logic Expression based Spatial-Temporal Behavior Understanding in Videos and Its Application, NSFC 2016.1-2018.12

Traditional methods of video analysis lack of explicit representation of temporal information, which makes the rich temporal relationship couldn't be fully explored. Based on the general expression of temporal logic for video event description, this proposal mainly research the task of behavior understanding including feature extraction and motion representation, behavior recognition and high-level behavior understanding. In view of the existing characterization methods considering only spatial and simple temporal features, this proposal researches the spatial-temporal characterization which contains the rich temporal information. Thinking that events are always ambiguity themselves, this proposal studies a soft clustering method to learn the generated trajectories and then divide them into multiple possible event classes. On this basis, temporal pattern is modeled for video event with empty time-series and without calibration though temporal pattern mining, then the rich temporal structure and temporal dependencies among behaviors are mined to enhance the spatial detection. Finally, the probabilistic model is adopted to achieve correspondence-free behavior understanding with complex scene in multi-camera networks with arbitrary topology and eventually achieve the abnormal detection in both spatial and temporal level.


#### Interactive Image Retrieval Method Based on Probabilistic Hypergraph and Transductive Learning, NSFC 2016.1-2018.12
To bridge the semantic gap that exists between the representation of an image by low-level features and its high-level semantic content as perceived by humans, and to meet user-specific requirements, interactive image retrieval technology has drawn millions of researchersâ€™ interest. However, there are still some problems which have not been solved very well. This project focuses on the key problems of the interactive image retrieval technology. Firstly, for the non-structural content of image, the image is proposed to be modeled by a probabilistic hypergraph. Different kinds of feature points of image are considered as the nodes of the hypergraph. The probabilistic weight of the edges is computed using the information aggregation operator. These constitute an efficient hypergraph representation of image. Secondly, in order to capture the distribution of the image base efficiently and improve the retrieval performance, a probabilistic hypergraph model of the image based is developed. In this hypergraph, one image is taken as a node, and the edge structure is constructed by taking the similarity of images and regional density of the image base into account. This model can provide the constraint conditions of the consequential transductive learning. Thirdly, in aim to exploit the feedback information, this project investigates transductive learning method based on the probabilistic hypergraph. It mainly focuses on the construction of the objective function based on various norms, and the optimization of the solving algorithm. This project can not only enrich the theory of image analysis and recognition but also provide the theoretical basis for the recognition and retrieval of other multimedia.



#### Human Activity Understanding and Event Analysis based Multi-modal Vision, NSFC 2015.1-2018.12

The low illumination at night, and the low visibility of the heavy haze environment have brought huge challenges to the traditional video surveillance, while multimodal vision technology is an effective means to solve these problems. The frontal imaging part of the multimodal vision model employs the application popularization and color reducibility of visible videos, combined with the illumination independence and strong particle penetrability of infrared thermal videos; the back-end analysis utilizes the complementary characteristic of the multimodal video information, and then finally achieves the goal of intelligent video analysis in the harsh environment. On the basis of building the multimodal vision model, this project will focus on the scientific problems including object detection, object characteristic representation and recognition, multimodal object tracking, individual behavior recognition and group event analysis in the multimodal condition. The main tasks are to propose the sparse representation based background modeling algorithm and object tracking algorithm for the sparseness of multimodal data; to design the graphic representation based behavior recognition algorithm and event analysis algorithm on account of the relationship between the behavioral events; to constitute the complete algorithm framework with bottom-level processing, middle-level analysis and high-level semantic parsing for multimodal video data. The study of this project will powerfully boost the formation of the theoretical system and the application promotion of the all-time and all-weather intelligent video analysis.
